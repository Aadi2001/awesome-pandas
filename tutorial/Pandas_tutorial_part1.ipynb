{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "-"
   },
   "source": [
    "# Python for Data Analysis using Pandas (part 1 of 2)\n",
    "\n",
    "> The latest version of this notebook is always found at [github.com/tommyod/awesome-pandas](https://github.com/tommyod/awesome-pandas).   \n",
    "  Improvements, corrections or suggestions? **Please submit a [Pull Request](https://github.com/tommyod/awesome-pandas/pulls).**\n",
    "  \n",
    "  ![](pandas_vs_excel_vs_sas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "- **(1) Setup**\n",
    "  - (1.1) Installing Python and packages\n",
    "  - (1.2) Importing packages\n",
    "- **(2) Importing data**\n",
    "  - (2.1) Importing .csv files\n",
    "  - (2.2) Other ways of creating DataFrames\n",
    "  - (2.3) Changing names and data types\n",
    "- **(3) Summarizing data**\n",
    "  - (3.1) Peeking at the data\n",
    "  - (3.2) Null values and summary statistics\n",
    "  - (3.3) Unique values, value counts and sorting\n",
    "  - (3.4) Basic visualizations\n",
    "- **(4) Selecting and computing new columns**\n",
    "  - (4.1) Accessing rows, columns and data\n",
    "  - (4.2) Selecting subsets of columns\n",
    "  - (4.3) Selecting subsets of rows\n",
    "  - (4.4) Selecting subsets of rows *and* columns\n",
    "  - (4.5) Creating new columns\n",
    "  - (4.6) Applying functions\n",
    "  \n",
    "  \n",
    "**In the next video:** filtering and sorting, split-apply-combine, plotting, time series, machine learning, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.1) Installing Python and packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python and Anaconda\n",
    "\n",
    "If you haven't done it yet, you need to install Python.\n",
    "I recommend the [Anaconda Distribution](https://www.anaconda.com/download/), and you should install version `3.X`.\n",
    "- If you're on Windows, you will get a program called *Anaconda Prompt*. Open in and run `conda --version` to verify that everything works.\n",
    "- If you're on Linux, open a terminal and run `conda --version`.\n",
    "\n",
    "Type `conda list` to see every installed package, and `conda update --all` to update every package. Type `python` to open an interactive Python terminal, and `exit()` to leave.\n",
    "\n",
    "### NumPy, matplotlib and Pandas\n",
    "\n",
    "![](https://indranilsinharoy.files.wordpress.com/2013/01/scientificpythonecosystemsi.png?w=584&h=442)\n",
    "\n",
    "*Image source: https://indranilsinharoy.com/2013/01/06/python-for-scientific-computing-a-collection-of-resources/*\n",
    "\n",
    "To install indiviual packages, run `conda install <package>`.   \n",
    "The Anaconda distribution comes with 3 packages which this tutorial requires, namely [pandas](https://pandas.pydata.org/), [NumPy](http://www.numpy.org/) and [matplotlib](https://matplotlib.org/).\n",
    "We'll also briefly use [sklearn](https://scikit-learn.org/stable/).\n",
    "\n",
    "- **NumPy** implements $n$-dimensional arrays in Python for efficient numerical computations. See the [arXiv](https://arxiv.org/pdf/1102.1523.pdf) paper for a nice introduction. To learn basic NumPy, consider doing these [100 NumPy exercises](https://github.com/rougier/numpy-100). For an in-depth look at NumPy and vectorization to speed up scientific computing, see [From Python to Numpy\n",
    "](https://www.labri.fr/perso/nrougier/from-python-to-numpy/).\n",
    "- **Matplotlib** is the most popular library for plotting in Python. See the beautiful [gallery](https://matplotlib.org/gallery.html) to get an overview of the capabilities of matplotlib. Read the [Matplotlib tutorial](http://www.labri.fr/perso/nrougier/teaching/matplotlib/matplotlib.html) by Nicolas P. Rougier for an introduction.\n",
    "- **Pandas** is a library for data analysis based on two objects, the [Series](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html) and the [DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html).\n",
    "\n",
    "### Jupyter\n",
    "\n",
    "A [Jupyter Notebook](https://jupyter-notebook.readthedocs.io/en/stable/) is an environment for running Python code interactively, displaying graphs and working with data. Think of it as a tool with capabilities somewhere between a simple terminal and a full fledged IDE. Move to a directory using the `cd` command in the terminal, then run `jupyter notebook` to start up a notebook. A video introduction to JupyterLab is [JupyterLab: Building Blocks for Interactive Computing](https://www.youtube.com/watch?v=Ejh0ftSjk6g). See also this list of [28 Jupyter Notebook tips](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1.2) Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import KDEpy\n",
    "import sklearn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package versions\n",
    "\n",
    "To make this Jupyter Notebook more easily reproducible, we list versions of the libraries we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "print('Today is', datetime.datetime.utcnow())\n",
    "print('-'*2**6)\n",
    "\n",
    "for lib in [pd, np, matplotlib, KDEpy, sklearn]:\n",
    "    print(f'{lib.__name__.ljust(12)} version {lib.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Jupyter Notebooks\n",
    "\n",
    "- Useful shortcuts: `SHIFT + TAB`, `SHIFT + ENTER`, `ESC`, `ENTER`, `E`, `A`, `D,D`, `I, I`. Type `H` to see all shortcuts.\n",
    "- Executing terminal commands from within the notebook using `!`.\n",
    "- Using markdown and $\\LaTeX{}$.\n",
    "- Timing cells using `%%timeit` and other built-in magic commands.\n",
    "- Pitfalls when using notebooks: state, order of execution, tidyness.\n",
    "\n",
    "Example of $\\LaTeX{}$ usage in notebooks:\n",
    "\n",
    "$$0 \\leq\n",
    "  \\left[\\operatorname{tr}(\\mathbf{A} \\mathbf{B})\\right]^2 \\leq\n",
    "  \\operatorname{tr}\\left(\\mathbf{A}^2\\right) \\operatorname{tr}\\left(\\mathbf{B}^2\\right) \\leq\n",
    "  \\left[\\operatorname{tr}(\\mathbf{A})\\right]^2 \\left[\\operatorname{tr}(\\mathbf{B})\\right]^2$$\n",
    "$$\\varphi_X(t) = \\operatorname{E}\\left[\\exp \\left ({i\\int_\\mathbf{R} t(s)X(s)ds} \\right ) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Importing data\n",
    "\n",
    "Starting a cell with a `!` let's us use terminal commands. The UNIX `head` command shows the first rows of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.1) Importing `.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree . -L 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/movie_metadata.csv -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Interested in learning UNIX commands?** The book [The Linux Command Line](https://www.amazon.com/Linux-Command-Line-Complete-Introduction-ebook/dp/B006X2QEQS) gives a detailed introduction, and [Data Science at the Command Line](https://www.amazon.com/Data-Science-Command-Line-Time-Tested/dp/1491947853) shows how basic data manipulation may be done using the command line only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file has many columns, so we'll only load a couple into a pandas DataFrame.\n",
    "To familiarize ourselves with with [magic commands](http://ipython.readthedocs.io/en/stable/interactive/magics.html), we'll use `%%time` to time the execution of the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cols_to_use = ['movie_title', 'director_name', 'country', 'content_rating', 'imdb_score', 'gross']\n",
    "df = pd.read_csv(r'data/movie_metadata.csv', sep=',', usecols=cols_to_use)\n",
    "print(f'Loaded data of size {df.shape} into memory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)  # Show the top 2 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df.shape` attribute gives the rows and columns of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape  # Alternatively, use len(df) for row count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.2) Other ways of creating DataFrames\n",
    "\n",
    "**The DataFrame**\n",
    "\n",
    "> Two-dimensional size-mutable, potentially heterogeneous tabular data\n",
    "structure with **labeled axes** (rows and columns). Arithmetic operations\n",
    "align on both row and column labels. Can be thought of as a **dict-like\n",
    "container for Series objects**. The primary pandas data structure.\n",
    "\n",
    "**Creating a DataFrame from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'name':['Max', 'Mark', 'Mia'], 'age':[31, 25, 38]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading a HTML table from the web**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read HTML tables into a list of DataFrame objects.\n",
    "url = r'https://en.wikipedia.org/wiki/List_of_Germans_by_net_worth'\n",
    "tables = pd.read_html(url, header=0)\n",
    "\n",
    "df_net_worth = tables[0]\n",
    "\n",
    "# Asserts can be useful for sanity checks\n",
    "assert len(df_net_worth) > 0 \n",
    "assert df_net_worth.Name.is_unique\n",
    "\n",
    "\n",
    "df_net_worth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading from databases is also possible.**\n",
    "\n",
    "Reading from Microsoft SQL using `pyodbc` and `pd.read_sql(sql_code, connection)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "> **Gotcha.** Methods on DataFrames **return a new instance** by default. In other words, they behave like methods on *immutable* Python object, and not like methods on *mutable* objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists are MUTABLE\n",
    "scores = [6, 2, 4, 9, 1]\n",
    "scores.sort()  # Changes the object in-place, returns None\n",
    "print(scores)\n",
    "\n",
    "# Strings are IMMUTABLE\n",
    "my_name = 'tommy'\n",
    "my_name = my_name.capitalize()  # A new instance is returned\n",
    "print(my_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.3) Changing names and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter axes labels\n",
    "df_net_worth = (df_net_worth\n",
    "                .rename(columns={'Net worth (USD)': 'net_worth',\n",
    "                                'World ranking': 'world_ranking',\n",
    "                                'Sources of wealth': 'wealth_source'}))\n",
    "\n",
    "df.rename(columns=str.capitalize).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type of each column may be listed using `df.dtypes`. Automatic conversion is possible via `pd.to_numeric` and `pd.to_datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net_worth['net_worth_num'] = (df_net_worth['net_worth']\n",
    "                             .str.replace(' billion', '')\n",
    "                             .apply(float))\n",
    "\n",
    "df_net_worth.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting help\n",
    "\n",
    "There are many ways to help help on objects and methods.\n",
    "\n",
    "- Use `SHIFT TAB` in a notebook.\n",
    "- Use question marks in the notebook, e.g. `?df.sum`.\n",
    "- Use the built-in Python function `help`, e.g. `help(df.sum)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.sum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Summarizing data\n",
    "\n",
    "This section shows some important methods related to summarizing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.1) Peeking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three methods that are useful when peeking at the data are `df.head`, `df.tail` and `df.sample`.\n",
    "Head and tail are $\\mathcal{O}(1)$ operations, while sample is $\\mathcal{O}(n)$, where $n$ is the number of rows.\n",
    "For small datasets, this makes no difference in practice. We'll use `df.sample` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the first `n` rows.\n",
    "df.head(n=2)  # df.tail(n=2) returns the last rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=2, replace=False, weights=None, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.2) Null values and summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should make sure the data types are correct. To do so, we can use `df.dtypes`, or `df.info()` for some more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a concise summary of a DataFrame\n",
    "df.info(verbose=True, memory_usage=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some null values. Let's count them by chaining `df.isnull()` and `df.sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect missing values -> sum over rows\n",
    "null_values = df.isnull().sum(axis=0)\n",
    "null_values #  / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the above is not a DataFrame object, but a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://www.mathsisfun.com/algebra/images/scalar-vector-matrix.svg)\n",
    "*Image source:* https://www.mathsisfun.com/algebra/scalar-vector-matrix.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the output prettier by converting the `null_values` Series to a DataFrame using the `to_frame()` method, then transposing using `.T`, and finally renaming the first index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values.to_frame().T.rename(index={0: 'Missing values'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is called *method chaining*, and can be written like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    "    .isnull()    # Figure out whether every entry is null (missing), or not\n",
    "    .sum(axis=0) # Sum over each column, axis=0 is the default\n",
    "    .to_frame()  # The result is a Series, convert to DataFrame\n",
    "    .T           # Transpose (switch rows and columns)\n",
    "    .rename(index={0:'Missing values'}) # Rename the index and show it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tour of summarization would not be complete without `df.describe()`.  \n",
    "Calling `df.count()`, `df.nunique()`, `df.mean()`, `df.std()`, `df.min()`, `df.quantile()`, `df.max()` is also possible.\n",
    "\n",
    "> **Gotcha.** There are 200+ methods defined on a DataFrame. See the [API Reference](https://pandas.pydata.org/pandas-docs/stable/api.html) for an exhaustive list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[0.5], include='all').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='any').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=None).shape  # Use df[df.duplicated()] to see rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, how='any').drop_duplicates(subset=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.3) Unique values, value counts and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.content_rating.unique()  # Not the same as: df.content_rating.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.content_rating.drop_duplicates().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.content_rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['movie_title', 'gross']].nlargest(3, 'gross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by country, then by IMDB_score. Put NA values last\n",
    "df.sort_values(by=['country', 'imdb_score'], \n",
    "               ascending=[True, False], \n",
    "               na_position='last').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3.4) Basic visualizations\n",
    "\n",
    "Some quick visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.content_rating\n",
    " .value_counts()\n",
    " .to_frame()  # Below are the default values, except `figsize`\n",
    " .plot.barh(subplots=False, sharex=None, sharey=False, layout=None, \n",
    "            figsize=(10, 5), use_index=True, title=None, grid=None, legend=True, \n",
    "            style=None, logx=False, logy=False, loglog=False, xticks=None, \n",
    "            yticks=None, xlim=None, ylim=None, rot=None, fontsize=None, \n",
    "            colormap=None, table=False, yerr=None, xerr=None, \n",
    "            secondary_y=False, sort_columns=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gross.plot.kde(bw_method=0.1, grid=True, title='IMDB score', lw=3, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = pd.plotting.scatter_matrix(df, alpha=0.5, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Selecting and computing new columns\n",
    "\n",
    "This section is about selecting subsets of a datset, or creating new data from existing data, i.e.:\n",
    "\n",
    "- Selecting a **single column**, or a **subset of columns**.\n",
    "- Selecting a **subset of rows**, i.e. filtering.\n",
    "- Chaining and/or combining the above operations to accomplish both.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.1) Accessing index, columns and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very useful when using data with libraries\n",
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.gross.dropna().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.2) Selecting subsets of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())  # Get the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.director_name.head(3)  # Alternatively, use df['director_name'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting two or more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['movie_title', 'country']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most useful selection function is `df.loc[[row1, row2, ...], [col1, col2, ...]]`.\n",
    "\n",
    "- `df.loc[:, [col1, col2]]` selects every row, and columns `[col1, col2]`\n",
    "- `df.loc[[row1, row2], :]` selects rows `[row1, row2]`, and every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['movie_title', 'country']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df.loc[:, 'gross']  # Returns a Series\n",
    "b = df.loc[:, ['gross']]  # Returns a DataFrame\n",
    "\n",
    "print(type(a))\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of selecting a subset of columns to *keep*, we can select a subset to *drop*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified labels from rows or columns\n",
    "df.drop(columns=['director_name', 'gross', 'movie_title']).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer-location based indexing\n",
    "df.iloc[1:3, [0, 1, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.3) Selecting subsets of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the first `n` rows\n",
    "df.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a group of rows and columns by label(s) or a boolean array\n",
    "df.loc[[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top three movies / TV-series not from the USA\n",
    "df[df.country != 'USA'].nlargest(3, 'imdb_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best non-American films, with content rating PG-13\n",
    "mask = (df.country != 'USA') & (df.content_rating == 'PG-13')\n",
    "df[mask].nlargest(3, 'imdb_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.4) Selecting subsets of rows *and* columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above average movies, with the title containing 'ring'\n",
    "row_mask = ((df.imdb_score > df.imdb_score.mean()) & \n",
    "             df.movie_title.str.contains('ring'))\n",
    "df.loc[row_mask, ['director_name', 'movie_title', 'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns containing and underscore\n",
    "cols = [c for c in df.columns if '_' in c]\n",
    "df.loc[:, cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "numeric_cols = df.dtypes[df.dtypes == np.float].index.tolist()\n",
    "df.loc[:, numeric_cols].head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.5) Creating new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.copy()  # Copy the DataFrame\n",
    "\n",
    "# Create a new column - based on the gross income\n",
    "temp['log_gross'] = temp['gross'].apply(np.log10)\n",
    "\n",
    "temp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.plot.scatter(x='imdb_score', y='log_gross', alpha=0.2, s=15, figsize=(10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign new columns to a DataFrame, returning a new object\n",
    "# (a copy) with the new columns added to the original ones.\n",
    "(temp.assign(log_gross=lambda df:df.gross.apply(np.log10))).head()\n",
    "\n",
    "# One advantage is that method chaining can be used\n",
    "(temp\n",
    "     .assign(log_gross=lambda df:df.gross.apply(np.log10)) # Create a new column\n",
    "     .loc[:, ['country', 'content_rating', 'log_gross']] # Filter\n",
    "     .groupby(['country', 'content_rating']) # Group by and mean\n",
    "     .mean()\n",
    "     .reset_index() # Reset the index to sort\n",
    "     .sort_values(['country', 'log_gross'], ascending=[True, False]) # Sort the results\n",
    "     .set_index(['country', 'content_rating']) # Re-index\n",
    "     .assign(log_gross=lambda df:df.log_gross.round(2)) # Re-define the column and round it\n",
    "     .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.6) Applying functions\n",
    "\n",
    "On a `pd.Series`:\n",
    "\n",
    "- `pd.Series.map` applies an elementwise $f: \\mathbb{R} \\to \\mathbb{R}$ function (e.g. `str`, or `float`)\n",
    "- `pd.Series.apply` applies a vectorized $f: \\mathbb{R}^n \\to \\mathbb{R}^n$ function  (e.g. `log`, or `sin`)\n",
    "- `pd.Series.aggregate` applies an aggreation $f: \\mathbb{R}^n \\to \\mathbb{R}$ function  (e.g. `mean`, or `std`)\n",
    "\n",
    "On a `pd.DataFrame`:\n",
    "\n",
    "- `pd.DataFrame.applymap` applies an elementwise $f: \\mathbb{R} \\to \\mathbb{R}$ function to every element\n",
    "- `pd.DataFrame.apply` applies a vectorized $f: \\mathbb{R}^n \\to \\mathbb{R}^n$ function to every element\n",
    "- `pd.DataFrame.aggregate` applies an aggreation $f: \\mathbb{R}^n \\to \\mathbb{R}$ function over an axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions on Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map values of Series using input correspondence (a dict, Series, or function).\n",
    "df.gross.map(float).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries are also maps, but brittle since no keys maps to NaN\n",
    "(df.content_rating\n",
    "    .map({'PG-13':'inappropriate for children under 13', \n",
    "          'PG': 'may not be suitable for children'}, na_action='ignore')\n",
    "    .value_counts(dropna=False)\n",
    "    .to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df.apply` method applies a NumPy [ufunc](https://docs.scipy.org/doc/numpy-1.15.1/reference/ufuncs.html).\n",
    "\n",
    "> A *universal function* (or ufunc for short) is a function that operates on ndarrays in an **element-by-element** fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke function on values of Series. Can be ufunc (a NumPy function\n",
    "# that applies to the entire Series) or a Python function that only works\n",
    "# on single values\n",
    "df.gross.apply(np.log10).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate using one or more operations over the specified axis.\n",
    "df.gross.aggregate(np.mean, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "### Functions on DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['gross', 'imdb_score']].apply(np.log).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['gross', 'imdb_score']].applymap(int).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ['gross', 'imdb_score']].mean().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or specify your own aggregation function\n",
    "def spread(array):\n",
    "    return np.max(array) - np.min(array)\n",
    "\n",
    "df.loc[:, ['gross', 'imdb_score']].aggregate(spread, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next up ...\n",
    "\n",
    "**In the next video:** filtering and sorting, split-apply-combine, plotting, time series, machine learning, ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
